{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Analysis with Data Science & Machine Learning - Part 1\n",
    "## Data Loading and Exploration\n",
    "\n",
    "This notebook performs the initial data loading and exploratory analysis of financial indicators for US stocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import kagglehub\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('ggplot')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Display all columns and rows\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Download the dataset using kagglehub\n",
    "path = kagglehub.dataset_download(\"cnic92/200-financial-indicators-of-us-stocks-20142018\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# List all files in the downloaded dataset\n",
    "data_files = os.listdir(path)\n",
    "print(\"Files in the dataset:\")\n",
    "for file in data_files:\n",
    "    print(f\"- {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the dataset (assuming CSV format, adjust if needed)\n",
    "# Try to find the main data file\n",
    "csv_files = [f for f in data_files if f.endswith('.csv')]\n",
    "if csv_files:\n",
    "    main_file = os.path.join(path, csv_files[0])\n",
    "    data = pd.read_csv(main_file)\n",
    "    print(f\"Loaded data from {csv_files[0]}\")\n",
    "else:\n",
    "    print(\"No CSV files found. Please check the dataset structure.\")\n",
    "    # Alternative: try to directly access a known file if the structure is known\n",
    "    # data = pd.read_csv(os.path.join(path, 'financial_data.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initial Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"Dataset shape:\", data.shape)\n",
    "print(\"\\nFirst 5 rows of the dataset:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Data types and missing values\n",
    "print(\"\\nData types:\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "missing_percent = (missing_values / len(data)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Values': missing_values,\n",
    "    'Percentage': missing_percent\n",
    "})\n",
    "\n",
    "# Display columns with missing values\n",
    "missing_df = missing_df[missing_df['Missing Values'] > 0].sort_values('Missing Values', ascending=False)\n",
    "if not missing_df.empty:\n",
    "    print(\"\\nColumns with missing values:\")\n",
    "    missing_df\n",
    "else:\n",
    "    print(\"\\nNo missing values found in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Statistical summary of numerical features\n",
    "print(\"\\nStatistical summary of numerical features:\")\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Count of companies by sector\n",
    "if 'Sector' in data.columns:\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sector_counts = data['Sector'].value_counts()\n",
    "    sns.barplot(x=sector_counts.values, y=sector_counts.index)\n",
    "    plt.title('Number of Companies by Sector')\n",
    "    plt.xlabel('Count')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nCompany count by sector:\")\n",
    "    print(sector_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Handling Missing Values and Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Function to identify and handle outliers\n",
    "def handle_outliers(df, column, method='cap', threshold=3):\n",
    "    \"\"\"Handle outliers in a dataframe column\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas DataFrame\n",
    "        The dataframe containing the column with outliers\n",
    "    column : str\n",
    "        The column name to check for outliers\n",
    "    method : str, optional (default='cap')\n",
    "        The method to handle outliers ('cap' or 'remove')\n",
    "    threshold : float, optional (default=3)\n",
    "        The z-score threshold to identify outliers\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas DataFrame\n",
    "        Dataframe with handled outliers\n",
    "    \"\"\"\n",
    "    # Create a copy of the dataframe\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Skip non-numeric columns\n",
    "    if not np.issubdtype(df_clean[column].dtype, np.number):\n",
    "        print(f\"Column '{column}' is not numeric. Skipping.\")\n",
    "        return df_clean\n",
    "    \n",
    "    # Calculate z-scores\n",
    "    z_scores = np.abs((df_clean[column] - df_clean[column].mean()) / df_clean[column].std())\n",
    "    outliers = z_scores > threshold\n",
    "    \n",
    "    # Handle outliers based on the selected method\n",
    "    if method == 'cap':\n",
    "        # Cap outliers at the threshold value\n",
    "        upper_bound = df_clean[column].mean() + threshold * df_clean[column].std()\n",
    "        lower_bound = df_clean[column].mean() - threshold * df_clean[column].std()\n",
    "        \n",
    "        # Cap upper and lower bounds\n",
    "        df_clean.loc[df_clean[column] > upper_bound, column] = upper_bound\n",
    "        df_clean.loc[df_clean[column] < lower_bound, column] = lower_bound\n",
    "        \n",
    "        print(f\"Capped {outliers.sum()} outliers in '{column}'\")\n",
    "    elif method == 'remove':\n",
    "        # Remove rows with outliers\n",
    "        df_clean = df_clean[~outliers]\n",
    "        print(f\"Removed {outliers.sum()} outliers from '{column}'\")\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Clean the data - handle missing values\n",
    "# Strategy depends on the actual data, but here's a generic approach\n",
    "data_clean = data.copy()\n",
    "\n",
    "# 1. Drop columns with too many missing values (e.g., >50%)\n",
    "high_missing_cols = missing_df[missing_df['Percentage'] > 50].index.tolist()\n",
    "if high_missing_cols:\n",
    "    print(f\"Dropping columns with >50% missing values: {high_missing_cols}\")\n",
    "    data_clean = data_clean.drop(columns=high_missing_cols)\n",
    "\n",
    "# 2. Impute remaining missing values - numerical columns with median, categorical with mode\n",
    "numeric_cols = data_clean.select_dtypes(include=np.number).columns\n",
    "categorical_cols = data_clean.select_dtypes(exclude=np.number).columns\n",
    "\n",
    "# For numeric columns: use median (more robust to outliers than mean)\n",
    "for col in numeric_cols:\n",
    "    if data_clean[col].isnull().sum() > 0:\n",
    "        median_val = data_clean[col].median()\n",
    "        data_clean[col].fillna(median_val, inplace=True)\n",
    "        print(f\"Filled missing values in '{col}' with median: {median_val:.2f}\")\n",
    "\n",
    "# For categorical columns: use mode (most frequent value)\n",
    "for col in categorical_cols:\n",
    "    if data_clean[col].isnull().sum() > 0:\n",
    "        mode_val = data_clean[col].mode()[0]\n",
    "        data_clean[col].fillna(mode_val, inplace=True)\n",
    "        print(f\"Filled missing values in '{col}' with mode: {mode_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Handle outliers in key financial metrics\n",
    "key_metrics = ['Total Revenue', 'Gross Profit', 'Operating Income', 'Net Income', \n",
    "               'Total Assets', 'Total Liabilities', 'Equity', 'Cash and Cash Equivalents',\n",
    "               'Earnings Per Share (EPS)', 'Price-to-Earnings Ratio (P/E)', 'Dividend Yield', \n",
    "               'Market Capitalization']\n",
    "\n",
    "# Handle outliers for each key metric that exists in our data\n",
    "for metric in key_metrics:\n",
    "    if metric in data_clean.columns:\n",
    "        data_clean = handle_outliers(data_clean, metric, method='cap', threshold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save cleaned data for next notebooks\n",
    "data_clean.to_csv('cleaned_financial_data.csv', index=False)\n",
    "print(\"Saved cleaned data to 'cleaned_financial_data.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Profile Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Display summary of the cleaned dataset\n",
    "print(\"Cleaned dataset shape:\", data_clean.shape)\n",
    "print(f\"Original dataset had {data.shape[0]} rows and {data.shape[1]} columns\")\n",
    "print(f\"Cleaned dataset has {data_clean.shape[0]} rows and {data_clean.shape[1]} columns\")\n",
    "\n",
    "# Check for any remaining missing values\n",
    "remaining_missing = data_clean.isnull().sum().sum()\n",
    "print(f\"Remaining missing values: {remaining_missing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "In the next notebook, we will:\n",
    "1. Calculate financial ratios\n",
    "2. Perform more detailed exploratory data analysis\n",
    "3. Create visualizations to understand the relationships between financial variables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
